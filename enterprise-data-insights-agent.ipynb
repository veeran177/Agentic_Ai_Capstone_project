{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":121144,"databundleVersionId":14484960,"sourceType":"competition"},{"sourceId":13911521,"sourceType":"datasetVersion","datasetId":8864069}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**AI-Powered Enterprise Data Insights Agent for Automated Business Intelligence**\n\nEnterprises generate large volumes of structured data (customer data, sales, campaigns, operations).\nHowever:\n\n* Manual analysis is slow\n\n* Insights depend heavily on analyst expertise\n\n* Reports are inconsistent\n\n* Non-technical teams (sales, marketing, operations) cannot extract insights without a data team\n\n* Traditional dashboards only show surface-level metrics\n\nResult: organizations fail to make timely, data-driven decisions.","metadata":{}},{"cell_type":"code","source":"# 1. Imports and set-up\n\nimport os\nimport json\nimport time\nimport logging\nfrom datetime import datetime\nfrom pprint import pprint\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Optional libs\ntry:\n    from imblearn.over_sampling import SMOTE\n    HAVE_SMOTE = True\nexcept Exception:\n    HAVE_SMOTE = False\n\ntry:\n    from xgboost import XGBClassifier\n    HAVE_XGB = True\nexcept Exception:\n    HAVE_XGB = False\n\nprint(\"HAVE_SMOTE:\", HAVE_SMOTE, \"HAVE_XGB:\", HAVE_XGB)\n\n# Observability: logging\nLOGFILE = \"agent_trace.log\"\nlogging.basicConfig(filename=LOGFILE, level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\ndef log(msg, level=\"info\"):\n    getattr(logging, level)(msg)\n    print(msg)\n\n# JSON-safety helper\ndef convert_json_safe(obj):\n    \"\"\"Recursively convert numpy types and non-json-serializable keys to json-safe types.\"\"\"\n    if isinstance(obj, dict):\n        out = {}\n        for k, v in obj.items():\n            # convert keys to str (JSON requires string keys)\n            if isinstance(k, (np.integer, np.int64, np.int32)):\n                k2 = int(k)\n            else:\n                k2 = str(k)\n            out[k2] = convert_json_safe(v)\n        return out\n    elif isinstance(obj, list):\n        return [convert_json_safe(i) for i in obj]\n    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n        return int(obj)\n    elif isinstance(obj, (np.floating, np.float64)):\n        return float(obj)\n    elif isinstance(obj, (np.ndarray,)):\n        return obj.tolist()\n    else:\n        return obj","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:22:21.298033Z","iopub.execute_input":"2025-11-29T12:22:21.298586Z","iopub.status.idle":"2025-11-29T12:22:26.820601Z","shell.execute_reply.started":"2025-11-29T12:22:21.298469Z","shell.execute_reply":"2025-11-29T12:22:26.819604Z"}},"outputs":[{"name":"stdout","text":"HAVE_SMOTE: False HAVE_XGB: True\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# 2. Dataset loader (handles semicolon separated bank-full.csv)\ndef load_bank_dataset(path=\"/mnt/data/bank-full.csv\"):\n    if not os.path.exists(path):\n        # try common Kaggle input paths\n        candidates = [\n            \"/kaggle/input/bank-marketing-dataset/bank-full.csv\",\n            \"/kaggle/input/bank-marketing-dataset/bank.csv\",\n            \"../input/bank-marketing-dataset/bank-full.csv\",\n            \"../input/bank-marketing-dataset/bank.csv\"\n        ]\n        for c in candidates:\n            if os.path.exists(c):\n                path = c\n                break\n    if not os.path.exists(path):\n        raise FileNotFoundError(f\"Bank dataset not found at {path}. Upload `bank-full.csv` or add the Kaggle dataset.\")\n    df = pd.read_csv(path, sep=';')\n    log(f\"Loaded dataset from {path} shape={df.shape}\")\n    return df\n\ndf = load_bank_dataset(\"/mnt/data/bank-full.csv\")\ndisplay(df.head())\nprint(\"Columns:\", df.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:22:26.822177Z","iopub.execute_input":"2025-11-29T12:22:26.822585Z","iopub.status.idle":"2025-11-29T12:22:27.038481Z","shell.execute_reply.started":"2025-11-29T12:22:26.822559Z","shell.execute_reply":"2025-11-29T12:22:27.037065Z"}},"outputs":[{"name":"stdout","text":"Loaded dataset from /kaggle/input/bank-marketing-dataset/bank-full.csv shape=(45211, 17)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   age           job  marital  education default  balance housing loan  \\\n0   58    management  married   tertiary      no     2143     yes   no   \n1   44    technician   single  secondary      no       29     yes   no   \n2   33  entrepreneur  married  secondary      no        2     yes  yes   \n3   47   blue-collar  married    unknown      no     1506     yes   no   \n4   33       unknown   single    unknown      no        1      no   no   \n\n   contact  day month  duration  campaign  pdays  previous poutcome   y  \n0  unknown    5   may       261         1     -1         0  unknown  no  \n1  unknown    5   may       151         1     -1         0  unknown  no  \n2  unknown    5   may        76         1     -1         0  unknown  no  \n3  unknown    5   may        92         1     -1         0  unknown  no  \n4  unknown    5   may       198         1     -1         0  unknown  no  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>58</td>\n      <td>management</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>2143</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>261</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44</td>\n      <td>technician</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>29</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>151</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>entrepreneur</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>2</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>76</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>1506</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>92</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33</td>\n      <td>unknown</td>\n      <td>single</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>1</td>\n      <td>no</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>198</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Columns: ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 3. Basic cleaning, target mapping, engineering\n# Map target to numeric (if not already)\nif 'y' in df.columns:\n    if not np.issubdtype(df['y'].dtype, np.number):\n        df['y'] = df['y'].map({'yes': 1, 'no': 0})\n        log(\"Mapped 'y' to numeric 1/0\")\n\n# Safety: drop 'duration' if it exists (some datasets include it; some do not)\nif 'duration' in df.columns:\n    df = df.drop(columns=['duration'])\n    log(\"Dropped 'duration' column (leakage mitigation)\")\n\n# Create pdays_never flag for 'pdays' if present\nif 'pdays' in df.columns:\n    df['pdays_never'] = (df['pdays'] == -1).astype(int)\n    log(\"Created 'pdays_never' flag (1 if pdays == -1)\")\n\n# Quick checks\nprint(\"Shape after cleaning:\", df.shape)\nprint(\"Missing values per column:\\n\", df.isnull().sum())\nprint(\"Target distribution:\\n\", df['y'].value_counts().to_dict())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:22:43.218321Z","iopub.execute_input":"2025-11-29T12:22:43.218664Z","iopub.status.idle":"2025-11-29T12:22:43.282571Z","shell.execute_reply.started":"2025-11-29T12:22:43.218639Z","shell.execute_reply":"2025-11-29T12:22:43.281722Z"}},"outputs":[{"name":"stdout","text":"Mapped 'y' to numeric 1/0\nDropped 'duration' column (leakage mitigation)\nCreated 'pdays_never' flag (1 if pdays == -1)\nShape after cleaning: (45211, 17)\nMissing values per column:\n age            0\njob            0\nmarital        0\neducation      0\ndefault        0\nbalance        0\nhousing        0\nloan           0\ncontact        0\nday            0\nmonth          0\ncampaign       0\npdays          0\nprevious       0\npoutcome       0\ny              0\npdays_never    0\ndtype: int64\nTarget distribution:\n {0: 39922, 1: 5289}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 4. Discover numeric/categorical columns dynamically (avoid hardcoding)\n# excluded the target from feature lists\ntarget_col = 'y' if 'y' in df.columns else None\n\nnumeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\nif target_col and target_col in numeric_cols:\n    numeric_cols.remove(target_col)\n# keep 'pdays_never' as numeric if present but it might already be included\n# it's okay if numeric_cols contains pdays or pdays_never â€” preprocessor will handle it\n\ncategorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\nif target_col and target_col in categorical_cols:\n    categorical_cols.remove(target_col)\n\nlog(f\"Numeric cols detected: {numeric_cols}\")\nlog(f\"Categorical cols detected: {categorical_cols}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:22:50.066555Z","iopub.execute_input":"2025-11-29T12:22:50.066874Z","iopub.status.idle":"2025-11-29T12:22:50.085438Z","shell.execute_reply.started":"2025-11-29T12:22:50.066850Z","shell.execute_reply":"2025-11-29T12:22:50.084186Z"}},"outputs":[{"name":"stdout","text":"Numeric cols detected: ['age', 'balance', 'day', 'campaign', 'pdays', 'previous', 'pdays_never']\nCategorical cols detected: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# 5. Build robust preprocessing pipeline (handles empty cat/num gracefully)\ndef build_preprocessor(num_cols, cat_cols):\n    transformers = []\n    if len(num_cols) > 0:\n        num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scale', StandardScaler())])\n        transformers.append(('num', num_pipe, num_cols))\n    if len(cat_cols) > 0:\n        cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='unknown')), ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n        transformers.append(('cat', cat_pipe, cat_cols))\n    if len(transformers) == 0:\n        raise RuntimeError(\"No numeric or categorical columns found for preprocessing.\")\n    pre = ColumnTransformer(transformers=transformers, remainder='drop')\n    return pre\n\npreprocessor = build_preprocessor(numeric_cols, categorical_cols)\nlog(\"Preprocessor built successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:22:56.054203Z","iopub.execute_input":"2025-11-29T12:22:56.054530Z","iopub.status.idle":"2025-11-29T12:22:56.062522Z","shell.execute_reply.started":"2025-11-29T12:22:56.054506Z","shell.execute_reply":"2025-11-29T12:22:56.061370Z"}},"outputs":[{"name":"stdout","text":"Preprocessor built successfully\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# 6. EDA \ndef automated_eda(df, target_col='y', out_dir='figs'):\n    os.makedirs(out_dir, exist_ok=True)\n    numeric = numeric_cols\n    cat = categorical_cols\n    # small histograms for first few numerics\n    for c in numeric[:5]:\n        plt.figure(figsize=(4,3))\n        df[c].hist(bins=30)\n        plt.title(f\"hist: {c}\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(out_dir, f\"hist_{c}.png\"))\n        plt.close()\n    # target distribution\n    if target_col in df.columns:\n        plt.figure(figsize=(4,3))\n        df[target_col].value_counts().plot.bar()\n        plt.title(\"target distribution\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(out_dir, \"target_distribution.png\"))\n        plt.close()\n    # sample head saved as json text for trace\n    head = df.head(3).to_dict(orient='records')\n    log(\"EDA artifacts saved to 'figs/'\")\n    return {'numeric': numeric, 'categorical': cat, 'head': head}\n\neda_summary = automated_eda(df, target_col=target_col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:23:04.298845Z","iopub.execute_input":"2025-11-29T12:23:04.299656Z","iopub.status.idle":"2025-11-29T12:23:05.664426Z","shell.execute_reply.started":"2025-11-29T12:23:04.299624Z","shell.execute_reply":"2025-11-29T12:23:05.663346Z"}},"outputs":[{"name":"stdout","text":"EDA artifacts saved to 'figs/'\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 7. Train/test split + imbalance detection\nX = df.drop(columns=[target_col]) if target_col else df.copy()\ny = df[target_col].values if target_col else None\n\n# ensure dataset has enough rows\nif X.shape[0] == 0:\n    raise RuntimeError(\"Empty dataset after preprocessing. Aborting.\")\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\nlog(f\"Split performed: X_train {X_train.shape}, X_test {X_test.shape}\")\n\nfrom collections import Counter\ncounts = dict(Counter(y))\nratio = (counts.get(0,0) / counts.get(1,1)) if counts.get(1,0) > 0 else np.inf\nimbalance = {'counts': counts, 'ratio': float(ratio), 'is_imbalanced': ratio > 4.0}\nlog(f\"Class distribution: {imbalance}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:23:42.427252Z","iopub.execute_input":"2025-11-29T12:23:42.427954Z","iopub.status.idle":"2025-11-29T12:23:42.480531Z","shell.execute_reply.started":"2025-11-29T12:23:42.427922Z","shell.execute_reply":"2025-11-29T12:23:42.479584Z"}},"outputs":[{"name":"stdout","text":"Split performed: X_train (36168, 16), X_test (9043, 16)\nClass distribution: {'counts': {0: 39922, 1: 5289}, 'ratio': 7.548118737001324, 'is_imbalanced': True}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# 8. Training helpers (safe) and model candidates\ndef train_with_preprocessor(model, X_train, y_train, preprocessor, X_test, y_test, use_smote=False):\n    # Fit preprocess on training set\n    X_train_p = preprocessor.fit_transform(X_train)\n    X_test_p = preprocessor.transform(X_test)\n    # Optional SMOTE (applied after preprocessing)\n    if use_smote and HAVE_SMOTE:\n        sm = SMOTE(random_state=42)\n        X_train_p, y_train = sm.fit_resample(X_train_p, y_train)\n    model.fit(X_train_p, y_train)\n    y_pred = model.predict(X_test_p)\n    try:\n        y_prob = model.predict_proba(X_test_p)[:,1]\n    except Exception:\n        y_prob = None\n    metrics = {\n        'accuracy': float(accuracy_score(y_test, y_pred)),\n        'precision': float(precision_score(y_test, y_pred, zero_division=0)),\n        'recall': float(recall_score(y_test, y_pred, zero_division=0)),\n        'f1': float(f1_score(y_test, y_pred, zero_division=0))\n    }\n    if y_prob is not None:\n        try:\n            metrics['roc_auc'] = float(roc_auc_score(y_test, y_prob))\n        except Exception:\n            metrics['roc_auc'] = None\n    cm = confusion_matrix(y_test, y_pred).tolist()\n    return {'model': model, 'metrics': metrics, 'confusion_matrix': cm, 'preprocessor': preprocessor}\n\n# Quick models for demo\nmodels = [\n    ('LogisticRegression_balanced', LogisticRegression(max_iter=1000, class_weight='balanced')),\n    ('RandomForest_quick', RandomForestClassifier(n_estimators=80, max_depth=10, n_jobs=1, class_weight='balanced', random_state=42))\n]\nif HAVE_XGB:\n    models.append(('XGBoost_quick', XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, tree_method='hist')))\n\n# Use SMOTE only if available and imbalance detected\nuse_smote = HAVE_SMOTE and imbalance['is_imbalanced']\nlog(f\"SMOTE enabled: {use_smote}\")\n\nresults = []\nfor name, mdl in models:\n    log(f\"Starting training: {name}\")\n    start = time.time()\n    try:\n        # For tree models, sample a subset of training set for speed on demo\n        samp_frac = 1.0\n        if 'RandomForest' in name or 'XGBoost' in name:\n            samp_frac = 0.5\n        if samp_frac < 1.0:\n            X_train_sub = X_train.sample(frac=samp_frac, random_state=42)\n            y_train_sub = y_train[X_train_sub.index]\n        else:\n            X_train_sub, y_train_sub = X_train, y_train\n        res = train_with_preprocessor(mdl, X_train_sub, y_train_sub, preprocessor, X_test, y_test, use_smote=use_smote)\n        res['name'] = name\n        res['train_time_sec'] = round(time.time() - start, 2)\n        results.append(res)\n        log(f\"Finished {name} in {res['train_time_sec']}s. Metrics: {res['metrics']}\")\n    except Exception as e:\n        log(f\"Training failed for {name}: {e}\", level=\"error\")\n\nif len(results) == 0:\n    raise RuntimeError(\"No models produced results. Check training logs.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:23:52.010199Z","iopub.execute_input":"2025-11-29T12:23:52.010687Z","iopub.status.idle":"2025-11-29T12:23:53.475548Z","shell.execute_reply.started":"2025-11-29T12:23:52.010661Z","shell.execute_reply":"2025-11-29T12:23:53.474442Z"}},"outputs":[{"name":"stdout","text":"SMOTE enabled: False\nStarting training: LogisticRegression_balanced\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Finished LogisticRegression_balanced in 1.43s. Metrics: {'accuracy': 0.7550591617825942, 'precision': 0.26626262626262626, 'recall': 0.6228733459357277, 'f1': 0.3730540617039343, 'roc_auc': 0.7722321981314207}\nStarting training: RandomForest_quick\nTraining failed for RandomForest_quick: index 44782 is out of bounds for axis 0 with size 36168\nStarting training: XGBoost_quick\nTraining failed for XGBoost_quick: index 44782 is out of bounds for axis 0 with size 36168\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 9. Choose best model (by F1) and compute light permutation importances (safe)\ndef choose_best_by(results, key='f1'):\n    best = None\n    best_score = -1\n    for r in results:\n        s = r['metrics'].get(key, 0)\n        if s > best_score:\n            best_score = s\n            best = r\n    return best\n\ntop = choose_best_by(results, 'f1')\nlog(f\"Selected top model: {top['name']} with metrics: {top['metrics']}\")\n\n# Try permutation importance lightly (n_repeats small)\nfi = None\ntry:\n    from sklearn.inspection import permutation_importance\n    log(\"Computing light permutation importance (n_repeats=3)\")\n    # Ensure we have a fitted preprocessor and model in top\n    X_test_p = top['preprocessor'].transform(X_test)\n    perm = permutation_importance(top['model'], X_test_p, y_test, n_repeats=3, random_state=42, n_jobs=1)\n    imps = perm.importances_mean\n    # reconstruct feature names best-effort\n    feat_names = []\n    try:\n        # numeric names first\n        feat_names.extend(numeric_cols)\n        # get cat feature names from ohe if present\n        for name, trans, cols in top['preprocessor'].transformers_:\n            if name == 'cat':\n                try:\n                    ohe = trans.named_steps['ohe']\n                    cat_names = list(ohe.get_feature_names_out(cols))\n                    feat_names.extend(cat_names)\n                except Exception:\n                    pass\n        if len(feat_names) == len(imps):\n            fi = dict(sorted(zip(feat_names, imps), key=lambda x: -x[1])[:20])\n        else:\n            # fallback: index-based names\n            fi = {f\"f_{i}\": float(imps[i]) for i in range(min(20, len(imps)))}\n    except Exception:\n        fi = {f\"f_{i}\": float(imps[i]) for i in range(min(20, len(imps)))}\n    log(\"Permutation importances computed.\")\nexcept Exception as e:\n    log(\"Permutation importance failed or timed out: \" + str(e), level=\"warning\")\n    fi = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:24:07.306792Z","iopub.execute_input":"2025-11-29T12:24:07.307140Z","iopub.status.idle":"2025-11-29T12:24:07.774743Z","shell.execute_reply.started":"2025-11-29T12:24:07.307113Z","shell.execute_reply":"2025-11-29T12:24:07.773861Z"}},"outputs":[{"name":"stdout","text":"Selected top model: LogisticRegression_balanced with metrics: {'accuracy': 0.7550591617825942, 'precision': 0.26626262626262626, 'recall': 0.6228733459357277, 'f1': 0.3730540617039343, 'roc_auc': 0.7722321981314207}\nComputing light permutation importance (n_repeats=3)\nPermutation importances computed.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 10. LLM stub for executive summary (replace with Gemini/OpenAI if you have API access)\ndef llm_summarize_stub(best_model_info, fi):\n    # Template-based simulated summary (safe for public notebook)\n    lines = []\n    lines.append(\"EXECUTIVE SUMMARY (Simulated LLM Output)\")\n    lines.append(f\"Top model: {best_model_info.get('name')}\")\n    metrics = best_model_info.get('metrics', {})\n    lines.append(\"Metrics:\")\n    lines.append(f\"- Accuracy: {metrics.get('accuracy'):.3f}\")\n    lines.append(f\"- Precision: {metrics.get('precision'):.3f}\")\n    lines.append(f\"- Recall: {metrics.get('recall'):.3f}\")\n    lines.append(f\"- F1-score: {metrics.get('f1'):.3f}\")\n    if metrics.get('roc_auc') is not None:\n        lines.append(f\"- ROC-AUC: {metrics.get('roc_auc'):.3f}\")\n    lines.append(\"\")\n    if fi:\n        lines.append(\"Top feature signals (approx):\")\n        for k, v in list(fi.items())[:8]:\n            lines.append(f\"- {k}: {v:.4f}\")\n    lines.append(\"\")\n    lines.append(\"Actionable recommendations:\")\n    lines.append(\"- Focus outreach on segments with positive signals; run A/B tests for model-based targeting.\")\n    lines.append(\"- Monitor model drift and fairness metrics before production rollout.\")\n    return \"\\n\".join(lines)\n\nexecutive_summary = llm_summarize_stub(top, fi)\nprint(\"Executive summary preview:\\n\", executive_summary[:800])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:24:16.148209Z","iopub.execute_input":"2025-11-29T12:24:16.148533Z","iopub.status.idle":"2025-11-29T12:24:16.157223Z","shell.execute_reply.started":"2025-11-29T12:24:16.148512Z","shell.execute_reply":"2025-11-29T12:24:16.156132Z"}},"outputs":[{"name":"stdout","text":"Executive summary preview:\n EXECUTIVE SUMMARY (Simulated LLM Output)\nTop model: LogisticRegression_balanced\nMetrics:\n- Accuracy: 0.755\n- Precision: 0.266\n- Recall: 0.623\n- F1-score: 0.373\n- ROC-AUC: 0.772\n\nTop feature signals (approx):\n- month_aug: 0.0436\n- pdays_never: 0.0371\n- poutcome_failure: 0.0345\n- month_jul: 0.0324\n- month_nov: 0.0323\n- poutcome_success: 0.0171\n- month_jan: 0.0126\n- month_feb: 0.0059\n\nActionable recommendations:\n- Focus outreach on segments with positive signals; run A/B tests for model-based targeting.\n- Monitor model drift and fairness metrics before production rollout.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# 11. Memory & artifacts saving (JSON-safe)\nMEMORY_FILE = \"agent_memory_capstone.json\"\ndef load_memory():\n    if os.path.exists(MEMORY_FILE):\n        try: return json.load(open(MEMORY_FILE,'r'))\n        except: return {}\n    return {}\n\ndef save_memory(mem):\n    with open(MEMORY_FILE,'w') as f:\n        json.dump(convert_json_safe(mem), f, indent=2)\n    log(\"Memory saved to \" + MEMORY_FILE)\n\nmemory = load_memory()\nmemory['last_run'] = {\n    'timestamp': datetime.utcnow().isoformat(),\n    'top_model': {'name': top['name'], 'metrics': top['metrics']},\n    'imbalance': imbalance\n}\nsave_memory(memory)\n\nartifacts = {\n    'timestamp': datetime.utcnow().isoformat(),\n    'data_shape': df.shape,\n    'top_model': {'name': top['name'], 'metrics': top['metrics']},\n    'models': [{ 'name': r['name'], 'metrics': r['metrics'] } for r in results],\n    'feature_importances': fi,\n    'imbalance': imbalance\n}\n\n# JSON-safe convert then save\nartifacts_safe = convert_json_safe(artifacts)\nwith open('agent_artifacts.json','w') as f:\n    json.dump(artifacts_safe, f, indent=2)\nwith open('executive_summary.txt','w') as f:\n    f.write(executive_summary)\n\nlog(\"Saved artifacts: agent_artifacts.json, executive_summary.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:24:24.658755Z","iopub.execute_input":"2025-11-29T12:24:24.659044Z","iopub.status.idle":"2025-11-29T12:24:24.669673Z","shell.execute_reply.started":"2025-11-29T12:24:24.659024Z","shell.execute_reply":"2025-11-29T12:24:24.668837Z"}},"outputs":[{"name":"stdout","text":"Memory saved to agent_memory_capstone.json\nSaved artifacts: agent_artifacts.json, executive_summary.txt\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# 12. Simple improvement loop (Loop Agent demo) - limited iterations\ndef improvement_loop(df, memory, max_iters=1, threshold_f1=0.45):\n    log(\"Starting improvement loop (demo, limited iters)\")\n    best_overall = memory.get('best_overall', {'f1': -1})\n    for i in range(max_iters):\n        log(f\"Improvement iteration {i+1}\")\n        # For demo we will retrain quickly by calling the training block with slightly different RF params\n        mdl = RandomForestClassifier(n_estimators=60 + 40*i, max_depth=12, n_jobs=1, class_weight='balanced', random_state=42)\n        try:\n            # reuse preprocessor fitted on full X_train\n            res = train_with_preprocessor(mdl, X_train, y_train, preprocessor, X_test, y_test, use_smote=use_smote)\n            f1 = res['metrics'].get('f1', 0)\n            log(f\"Iter {i+1} f1={f1}\")\n            if f1 > best_overall.get('f1', -1):\n                best_overall = {'f1': f1, 'model': 'RandomForest_iter_' + str(i+1), 'metrics': res['metrics']}\n                memory['best_overall'] = best_overall\n                save_memory(memory)\n            if f1 >= threshold_f1:\n                log(\"Threshold reached; stopping improvement loop.\")\n                break\n        except Exception as e:\n            log(\"Improvement iteration failed: \" + str(e), level=\"warning\")\n    return best_overall\n\nbest_overall = improvement_loop(df, memory, max_iters=1, threshold_f1=0.45)\nlog(f\"Improvement loop finished. best_overall: {best_overall}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:24:34.456190Z","iopub.execute_input":"2025-11-29T12:24:34.456496Z","iopub.status.idle":"2025-11-29T12:24:36.832541Z","shell.execute_reply.started":"2025-11-29T12:24:34.456475Z","shell.execute_reply":"2025-11-29T12:24:36.831429Z"}},"outputs":[{"name":"stdout","text":"Starting improvement loop (demo, limited iters)\nImprovement iteration 1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Iter 1 f1=0.45578231292517013\nMemory saved to agent_memory_capstone.json\nThreshold reached; stopping improvement loop.\nImprovement loop finished. best_overall: {'f1': 0.45578231292517013, 'model': 'RandomForest_iter_1', 'metrics': {'accuracy': 0.8407608094658852, 'precision': 0.3797229219143577, 'recall': 0.5699432892249527, 'f1': 0.45578231292517013, 'roc_auc': 0.7926273033203798}}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Cell 13: Observability sample: show tail of log file\nprint(\"\\n--- last log lines ---\")\nif os.path.exists(LOGFILE):\n    with open(LOGFILE,'r') as f:\n        tail = f.readlines()[-30:]\n    print(\"\".join(tail))\nelse:\n    print(\"No log file found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:24:45.763450Z","iopub.execute_input":"2025-11-29T12:24:45.763793Z","iopub.status.idle":"2025-11-29T12:24:45.771667Z","shell.execute_reply.started":"2025-11-29T12:24:45.763769Z","shell.execute_reply":"2025-11-29T12:24:45.770030Z"}},"outputs":[{"name":"stdout","text":"\n--- last log lines ---\n2025-11-29 12:22:27,006 INFO Loaded dataset from /kaggle/input/bank-marketing-dataset/bank-full.csv shape=(45211, 17)\n2025-11-29 12:22:43,233 INFO Mapped 'y' to numeric 1/0\n2025-11-29 12:22:43,242 INFO Dropped 'duration' column (leakage mitigation)\n2025-11-29 12:22:43,244 INFO Created 'pdays_never' flag (1 if pdays == -1)\n2025-11-29 12:22:50,081 INFO Numeric cols detected: ['age', 'balance', 'day', 'campaign', 'pdays', 'previous', 'pdays_never']\n2025-11-29 12:22:50,081 INFO Categorical cols detected: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n2025-11-29 12:22:56,057 INFO Preprocessor built successfully\n2025-11-29 12:23:05,660 INFO EDA artifacts saved to 'figs/'\n2025-11-29 12:23:42,468 INFO Split performed: X_train (36168, 16), X_test (9043, 16)\n2025-11-29 12:23:42,477 INFO Class distribution: {'counts': {0: 39922, 1: 5289}, 'ratio': 7.548118737001324, 'is_imbalanced': True}\n2025-11-29 12:23:52,020 INFO SMOTE enabled: False\n2025-11-29 12:23:52,021 INFO Starting training: LogisticRegression_balanced\n2025-11-29 12:23:53,448 INFO Finished LogisticRegression_balanced in 1.43s. Metrics: {'accuracy': 0.7550591617825942, 'precision': 0.26626262626262626, 'recall': 0.6228733459357277, 'f1': 0.3730540617039343, 'roc_auc': 0.7722321981314207}\n2025-11-29 12:23:53,448 INFO Starting training: RandomForest_quick\n2025-11-29 12:23:53,455 ERROR Training failed for RandomForest_quick: index 44782 is out of bounds for axis 0 with size 36168\n2025-11-29 12:23:53,456 INFO Starting training: XGBoost_quick\n2025-11-29 12:23:53,469 ERROR Training failed for XGBoost_quick: index 44782 is out of bounds for axis 0 with size 36168\n2025-11-29 12:24:07,313 INFO Selected top model: LogisticRegression_balanced with metrics: {'accuracy': 0.7550591617825942, 'precision': 0.26626262626262626, 'recall': 0.6228733459357277, 'f1': 0.3730540617039343, 'roc_auc': 0.7722321981314207}\n2025-11-29 12:24:07,343 INFO Computing light permutation importance (n_repeats=3)\n2025-11-29 12:24:07,771 INFO Permutation importances computed.\n2025-11-29 12:24:24,664 INFO Memory saved to agent_memory_capstone.json\n2025-11-29 12:24:24,666 INFO Saved artifacts: agent_artifacts.json, executive_summary.txt\n2025-11-29 12:24:34,461 INFO Starting improvement loop (demo, limited iters)\n2025-11-29 12:24:34,461 INFO Improvement iteration 1\n2025-11-29 12:24:36,826 INFO Iter 1 f1=0.45578231292517013\n2025-11-29 12:24:36,827 INFO Memory saved to agent_memory_capstone.json\n2025-11-29 12:24:36,827 INFO Threshold reached; stopping improvement loop.\n2025-11-29 12:24:36,829 INFO Improvement loop finished. best_overall: {'f1': 0.45578231292517013, 'model': 'RandomForest_iter_1', 'metrics': {'accuracy': 0.8407608094658852, 'precision': 0.3797229219143577, 'recall': 0.5699432892249527, 'f1': 0.45578231292517013, 'roc_auc': 0.7926273033203798}}\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# 14. Prepare README and submission snippet (auto-create)\nREADME = f\"\"\"\n# Enterprise Data-Insights Agent for Bank Marketing Campaigns\n\nAuthor: YOUR_NAME\nTrack: Enterprise Agents\n\nBrief: Agentic pipeline that ingests the Bank Marketing dataset, runs EDA, trains models, and generates an executive summary. Demonstrates agentic features: tools, session & memory, loop agent, and observability.\n\nArtifacts produced:\n- agent_artifacts.json\n- executive_summary.txt\n- agent_memory_capstone.json\n- agent_trace.log\n\nRun: paste this notebook into Kaggle and run cells top->down.\n\"\"\"\nwith open(\"README_capstone.md\",\"w\") as f:\n    f.write(README.strip())\nlog(\"README_capstone.md written\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:24:55.732111Z","iopub.execute_input":"2025-11-29T12:24:55.732524Z","iopub.status.idle":"2025-11-29T12:24:55.738913Z","shell.execute_reply.started":"2025-11-29T12:24:55.732496Z","shell.execute_reply":"2025-11-29T12:24:55.737934Z"}},"outputs":[{"name":"stdout","text":"README_capstone.md written\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# 15. Final summary prints\nprint(\"\\nFiles in workspace:\", [f for f in os.listdir('.') if f.endswith('.json') or f.endswith('.txt') or f.endswith('.log')])\nprint(\"Top model metrics:\", top['metrics'])\nprint(\"Executive summary (first 400 chars):\\n\", executive_summary[:400])\nprint(\"Notebook run complete. Replace llm_summarize_stub with real LLM calls for bonus points (Gemini).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:26:50.186412Z","iopub.execute_input":"2025-11-29T12:26:50.186786Z","iopub.status.idle":"2025-11-29T12:26:50.193020Z","shell.execute_reply.started":"2025-11-29T12:26:50.186762Z","shell.execute_reply":"2025-11-29T12:26:50.192029Z"}},"outputs":[{"name":"stdout","text":"\nFiles in workspace: ['agent_memory_capstone.json', 'agent_artifacts.json', 'executive_summary.txt', 'agent_trace.log']\nTop model metrics: {'accuracy': 0.7550591617825942, 'precision': 0.26626262626262626, 'recall': 0.6228733459357277, 'f1': 0.3730540617039343, 'roc_auc': 0.7722321981314207}\nExecutive summary (first 400 chars):\n EXECUTIVE SUMMARY (Simulated LLM Output)\nTop model: LogisticRegression_balanced\nMetrics:\n- Accuracy: 0.755\n- Precision: 0.266\n- Recall: 0.623\n- F1-score: 0.373\n- ROC-AUC: 0.772\n\nTop feature signals (approx):\n- month_aug: 0.0436\n- pdays_never: 0.0371\n- poutcome_failure: 0.0345\n- month_jul: 0.0324\n- month_nov: 0.0323\n- poutcome_success: 0.0171\n- month_jan: 0.0126\n- month_feb: 0.0059\n\nActionable reco\nNotebook run complete. Replace llm_summarize_stub with real LLM calls for bonus points (Gemini).\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# pseudocode - DO NOT paste keys into public repo\nfrom google.generativeai import client as gclient\ngclient.configure(api_key=os.environ['GEMINI_API_KEY'])\ndef llm_summarize(prompt):\n    resp = gclient.generate(text=prompt, model=\"gemini-1.5-pro\")\n    return resp.text\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}